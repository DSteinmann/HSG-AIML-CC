import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
import torch.nn.functional as F
import rasterio
import numpy as np
import pandas as pd
import os
import random
import time
import traceback
from pathlib import Path
from tqdm import tqdm
from typing import Tuple, List, Dict, Any, Optional, Callable
from sklearn.model_selection import train_test_split

# --- Configuration ---
CONFIG = {
    "model": {
        "load_path": Path('./convnext_2stage_imgnorm.pth'),  # Path for saving/loading model
        "num_classes": None,  # Determined dynamically
        "class_names": None,  # Determined dynamically
    },
    "data": {
        "train_dir": Path('./ds/images/remote_sensing/otherDatasets/sentinel_2/tif'),
        "validation_dir": Path('./testset/testset'),
        "image_size": 128,
        "batch_size": 32,
        "num_workers": 4,
        "train_ratio": 0.9,
    },
    "train": {
        "seed": 1337,
        "lr_stage1": 1e-3,
        "lr_stage2": 1e-3,
        "stage1_epochs": 30,
        "stage2_epochs": 30,
        "warmup_epochs": 3,
        "initial_warmup_lr": 1e-6,
        "weight_decay": 3.7553e-05,
        "optimizer_name": 'AdamW',
        "patience": 10,
    },
    "device": "cuda" if torch.cuda.is_available() else "cpu",
    "amp_enabled": True,
    "prediction": {
        "predictions_csv_path": Path('./outputs/track_2.csv'),
        "kaggle_competition": 'aicrowd-geospatial-challenge',
        "kaggle_message": 'Evaluation Script Submission',
        "submit_to_kaggle": False,
    }
}

# --- Device Setup ---
USE_CUDA = torch.cuda.is_available()
DEVICE = torch.device("cuda" if USE_CUDA else "cpu")
print(f"Using device: {DEVICE}")

# --- Seed Setting ---
def set_seed(seed: int):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(seed)
        torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False

set_seed(CONFIG["train"]["seed"])

# --- Data Loading and Preprocessing ---
def load_sentinel2_image(filepath: str) -> np.ndarray:
    """Loads a Sentinel-2 image (TIF or NPY), returns NumPy CHW (12 bands)."""
    if filepath.endswith('.tif'):
        with rasterio.open(filepath) as src:
            if src.count < 13:
                raise ValueError(f"Expected >=13 bands, got {src.count} in {filepath}")
            bands = list(range(1, 10)) + list(range(11, 14))  # Exclude B10
            image = src.read(bands)  # Shape: (12, H, W)

    elif filepath.endswith('.npy'):
        image = np.load(filepath)  # Load .npy as is, without modification

        if image.shape[0] != 13 and image.shape[0] != 12:
            raise ValueError(f"Unexpected shape for .npy {filepath}: {image.shape}")

    else:
        raise ValueError(f"Unsupported file type: {filepath}")

    return image.astype(np.float32)

def normalize_image_per_image(image_np: np.ndarray) -> np.ndarray:
    """Normalizes 12-channel NumPy image (C, H, W) using its own stats."""
    if image_np.ndim != 3 or image_np.shape[0] != 12:
        raise ValueError(f"Invalid shape for per-image normalization: {image_np.shape}. Expected (12, H, W).")

    mean = np.mean(image_np, axis=(1, 2), keepdims=True)  # Per-channel mean
    std = np.std(image_np, axis=(1, 2), keepdims=True)  # Per-channel std

    return (image_np - mean) / (std + 1e-7)  # Normalize & avoid division by zero

# --- Dataset Class (Using Per-Image Normalization) ---
class Sentinel2Dataset(Dataset):
    """Custom Dataset for Sentinel-2 images. Returns Tensor CHW (12 channels)."""
    def __init__(self, paths_labels, transform=None):
        self.paths_labels = paths_labels
        self.transform = transform

    def __len__(self):
        return len(self.paths_labels)

    def __getitem__(self, idx):
        image_path, label = self.paths_labels[idx]
        try:
            image_np = load_sentinel2_image(image_path) # NumPy (C, H, W)
            image_np = normalize_image_per_image(image_np) # Apply per-image normalization HERE

            image_tensor = torch.from_numpy(image_np.copy()).float() # Convert to tensor AFTER normalization
            label_tensor = torch.tensor(label, dtype=torch.long)

            if self.transform:
                image_tensor = self.transform(image_tensor) # Apply remaining transforms

            return image_tensor, label_tensor, image_path

        except Exception as e:
            print(f"Error loading/processing image {image_path}:")
            traceback.print_exc()
            return None, None, None # Signal error

# Prediction dataset also uses per-image normalization
class NpyPredictionDataset(Dataset):
    def __init__(self, root_dir, transform=None):
        self.root_dir = root_dir
        self.transform = transform
        self.file_paths = sorted([os.path.join(root_dir, f) for f in os.listdir(root_dir) if f.endswith('.npy')])
        if not self.file_paths: raise FileNotFoundError(f"No .npy files in {root_dir}")
        print(f"Found {len(self.file_paths)} .npy files for prediction.")

    def __len__(self):
        return len(self.file_paths)

    def __getitem__(self, idx):
        image_path = self.file_paths[idx]
        try:
            image_np = load_sentinel2_image(image_path) # NumPy (C, H, W)
            image_np = normalize_image_per_image(image_np) # Apply per-image normalization HERE
            image_tensor = torch.from_numpy(image_np.copy()).float() # Convert to tensor

            if self.transform:
                image_tensor = self.transform(image_tensor) # Apply remaining transforms

            return image_tensor, 0, image_path # Dummy label 0

        except Exception as e:
            print(f"Error loading/processing image {image_path}:")
            traceback.print_exc()
            return None, None, None

# --- Data Transforms  ---
class AddGaussianNoise(object):
    def __init__(self, mean=0., std=0.1):
        self.std = std
        self.mean = mean

    def __call__(self, tensor):
        return tensor + torch.randn(tensor.size()) * self.std + self.mean

    def __repr__(self):
        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)

class RandomChannelScale(object):
    def __init__(self, scale_range=(0.9, 1.1)):
        self.scale_range = scale_range

    def __call__(self, tensor):
        scale_factors = torch.rand(tensor.shape[0]) * (self.scale_range[1] - self.scale_range[0]) + self.scale_range[0]
        return tensor * scale_factors.view(tensor.shape[0], 1, 1)

    def __repr__(self):
        return self.__class__.__name__ + '(scale_range={0})'.format(self.scale_range)

train_transforms = transforms.Compose([
    transforms.RandomHorizontalFlip(),
    transforms.RandomVerticalFlip(),
    transforms.RandomRotation(degrees=20),
    transforms.RandomAffine(degrees=20, translate=(0.1, 0.1), scale=(0.9, 1.1)),  # Small affine transformations
    #transforms.ColorJitter(brightness=0.2, contrast=0.2),  # Slight brightness & contrast changes
    AddGaussianNoise(mean=0., std=0.05),  # Add Gaussian noise
    RandomChannelScale(scale_range=(0.9, 1.1)),  # Channel-wise scaling
    transforms.Resize((CONFIG["data"]["image_size"], CONFIG["data"]["image_size"]), antialias=True),
])

val_transforms = transforms.Compose([
    transforms.Resize((CONFIG["data"]["image_size"], CONFIG["data"]["image_size"]), antialias=True),
])

# --- Create Datasets ---
print("Creating and splitting dataset...")
full_dataset_paths_labels = []
class_to_idx_map = {}
class_names = []
idx_counter = 0
# Scan training directory
for class_name in sorted(os.listdir(CONFIG["data"]["train_dir"])):
     class_dir = os.path.join(CONFIG["data"]["train_dir"], class_name)
     if os.path.isdir(class_dir) and not class_name.startswith('.'):
         if class_name not in class_to_idx_map:
             class_to_idx_map[class_name] = idx_counter
             class_names.append(class_name)
             idx_counter += 1
         class_idx = class_to_idx_map[class_name]
         for filename in os.listdir(class_dir):
             if filename.lower().endswith(('.tif', '.tiff')):
                 full_dataset_paths_labels.append((os.path.join(class_dir, filename), class_idx))

num_classes = len(class_names)
if num_classes == 0: raise FileNotFoundError(f"No valid class folders found in {CONFIG['data']['train_dir']}")
print(f"Found {len(full_dataset_paths_labels)} training images in {num_classes} classes: {class_names}")

CONFIG["model"]["num_classes"] = num_classes
CONFIG["model"]["class_names"] = class_names

# Stratified Split
train_info, val_info = train_test_split(
    full_dataset_paths_labels, train_size=CONFIG["data"]["train_ratio"], random_state=CONFIG["train"]["seed"],
    stratify=[label for _, label in full_dataset_paths_labels]
)

# Create Dataset objects using the split lists
train_dataset = Sentinel2Dataset(train_info, transform=train_transforms)
val_tif_dataset = Sentinel2Dataset(val_info, transform=val_transforms)
final_validation_dataset = NpyPredictionDataset(str(CONFIG["data"]["validation_dir"]), transform=val_transforms) # Prediction set

# --- Create DataLoaders ---
def collate_fn(batch):
    """ Filter out None samples before creating batch """
    batch = list(filter(lambda x: x is not None and x[0] is not None, batch))
    if not batch: return None, None, None
    try:
        images = torch.stack([item[0] for item in batch])
        labels = torch.stack([item[1] for item in batch])
        paths = [item[2] for item in batch]
        return images, labels, paths
    except Exception as e:
        print(f"Error in collate_fn: {e}. Skipping batch.")
        # traceback.print_exc() # Can be verbose
        return None, None, None

train_loader = DataLoader(train_dataset, batch_size=CONFIG["data"]["batch_size"], shuffle=True, num_workers=CONFIG["data"]["num_workers"], generator=torch.Generator().manual_seed(CONFIG["train"]["seed"]), pin_memory=True, collate_fn=collate_fn)
val_loader_split = DataLoader(val_tif_dataset, batch_size=CONFIG["data"]["batch_size"], pin_memory=True, shuffle=False, num_workers=CONFIG["data"]["num_workers"], collate_fn=collate_fn)
final_pred_loader = DataLoader(final_validation_dataset, batch_size=CONFIG["data"]["batch_size"], shuffle=False, num_workers=CONFIG["data"]["num_workers"], pin_memory=True, collate_fn=collate_fn)
print("DataLoaders created.")

# --- Define the Model ---
# Mish Activation Function
class Mish(nn.Module):
    def forward(self, x):
        return x * torch.tanh(F.softplus(x))

# Squeeze-and-Excitation Block (Attention Mechanism)
class SEBlock(nn.Module):
    def __init__(self, channels, reduction=16):
        super().__init__()
        self.squeeze = nn.AdaptiveAvgPool2d(1)  # Global Average Pooling
        self.fc = nn.Sequential(
            nn.Conv2d(channels, channels // reduction, kernel_size=1, bias=False),
            Mish(),
            nn.Conv2d(channels // reduction, channels, kernel_size=1, bias=False),
            nn.Sigmoid()
        )

    def forward(self, x):
        return x * self.fc(self.squeeze(x))

# Improved Sentinel-2 Classifier
class Sentinel2Classifier(nn.Module):
    """ CNN with Residual Connections, Attention, Hybrid Pooling & Mish Activation """
    def __init__(self, num_classes):
        super().__init__()

        self.mish = Mish()

        # CNN Layers
        self.conv1 = nn.Conv2d(12, 64, kernel_size=3, padding=1)
        self.bn1 = nn.BatchNorm2d(64)
        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)
        self.bn2 = nn.BatchNorm2d(128)
        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)
        self.bn3 = nn.BatchNorm2d(256)
        self.conv4 = nn.Conv2d(256, 512, kernel_size=3, padding=1)
        self.bn4 = nn.BatchNorm2d(512)
        self.conv5 = nn.Conv2d(512, 1024, kernel_size=3, padding=1)
        self.bn5 = nn.BatchNorm2d(1024)

        # Attention Blocks
        self.se1 = SEBlock(64)
        self.se2 = SEBlock(128)
        self.se3 = SEBlock(256)
        self.se4 = SEBlock(512)
        self.se5 = SEBlock(1024)

        # Hybrid Pooling (Avg + Max)
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        self.max_pool = nn.AdaptiveMaxPool2d(1)

        # Fully Connected Layers
        self.fc1 = nn.Linear(1024, 512)
        self.fc2 = nn.Linear(512, 256)
        self.fc3 = nn.Linear(256, num_classes)
        self.dropout = nn.Dropout(0.5)

        # Residual 1x1 Convolutions
        self.res_conv1 = nn.Conv2d(12, 64, kernel_size=1) # First residual layer
        self.res_conv2 = nn.Conv2d(64, 128, kernel_size=1)
        self.res_conv3 = nn.Conv2d(128, 256, kernel_size=1)
        self.res_conv4 = nn.Conv2d(256, 512, kernel_size=1)
        self.res_conv5 = nn.Conv2d(512, 1024, kernel_size=1)

        self.apply(self._initialize_weights)

    def _initialize_weights(self, m):
        """ Xavier Initialization for Conv & Linear Layers """
        if isinstance(m, (nn.Conv2d, nn.Linear)):
            nn.init.xavier_uniform_(m.weight)
            if m.bias is not None:
                nn.init.zeros_(m.bias)

    def _apply_residual(self, x, residual):
        """ Apply residual connection (add 1x1 conv if channels mismatch) """
        if x.shape[1] != residual.shape[1]:  # If channel sizes differ
            residual = nn.Conv2d(residual.shape[1], x.shape[1], kernel_size=1, bias=False).to(x.device)(residual)
        return x + residual

    def forward(self, x):
        # Feature Extraction with Skip Connections & Attention
        residual = self.res_conv1(x) # Pass initial input through 1x1 conv to match channels
        x = self.mish(self.bn1(self.conv1(x)))
        x = self.se1(x) + residual  # Skip connection

        residual = self.res_conv2(x) # Adjust residual using 1x1 convolution
        x = self.mish(self.bn2(self.conv2(x)))
        x = self.se2(x) + residual  # Skip connection

        residual = self.res_conv3(x)
        x = self.mish(self.bn3(self.conv3(x)))
        x = self.se3(x) + residual  # Skip connection

        residual = self.res_conv4(x)
        x = self.mish(self.bn4(self.conv4(x)))
        x = self.se4(x) + residual  # Skip connection

        residual = self.res_conv5(x)
        x = self.mish(self.bn5(self.conv5(x)))
        x = self.se5(x) + residual  # Skip connection

        # Hybrid Pooling (Avg + Max)
        x = self.avg_pool(x) + self.max_pool(x)
        x = torch.flatten(x, 1)

        # Fully Connected Layers with Residuals
        residual = x
        x = self.mish(self.fc1(x))
        x = self.dropout(x) + residual  # Skip connection

        residual = x
        x = self.mish(self.fc2(x))
        x = self.dropout(x) + residual  # Skip connection

        x = self.fc3(x)  # Final classification layer
        return x

# --- Helper Function for Training/Validation Epoch ---
def run_epoch(model, loader, criterion, optimizer, scaler, device, is_training, epoch_num, num_epochs_total, current_lr, warmup_scheduler=None, current_stage_epoch=0, total_warmup_epochs=0):
    """Runs a single epoch of training or validation."""
    if is_training: model.train()
    else: model.eval()
    running_loss = 0.0
    correct_predictions = 0
    total_samples = 0
    start_time = time.time()
    context = torch.no_grad() if not is_training else torch.enable_grad()
    loader_desc = "Training" if is_training else "Validation"

    print(f'---> Starting Epoch {epoch_num}/{num_epochs_total} ({loader_desc}) | LR: {current_lr:.4e}')

    for batch_idx, batch_data in enumerate(loader):
        if batch_data is None or batch_data[0] is None: continue
        inputs, targets, _ = batch_data # Unpack

        inputs = inputs.to(device)
        targets = targets.to(device)

        # Autocast for forward pass
        with torch.amp.autocast(device_type=device.type, enabled=USE_CUDA):
            outputs = model(inputs)
            loss = criterion(outputs, targets)

        if is_training:
            optimizer.zero_grad(set_to_none=True)
            scaler.scale(loss).backward()
            scaler.step(optimizer)
            scaler.update()

        running_loss += loss.item() * inputs.size(0)
        _, predicted = torch.max(outputs, 1)
        correct_predictions += (predicted == targets).sum().item()
        total_samples += targets.size(0)

    epoch_loss = running_loss / total_samples
    epoch_acc = correct_predictions / total_samples
    epoch_duration = time.time() - start_time

    print(f'    Epoch Loss: {epoch_loss:.4f} | Accuracy: {epoch_acc:.4f} | Duration: {epoch_duration:.2f}s')
    return epoch_loss, epoch_acc

# --- Warmup Learning Rate Scheduler ---
def get_warmup_scheduler(optimizer, warmup_epochs, initial_lr, target_lr, total_iters_stage1):
        """Linear Warmup Scheduler."""
        def warmup_lr_scheduler(optimizer, iter_num):
            progress = float(iter_num) / float(max(1, total_iters_stage1 * warmup_epochs))
            lr = initial_lr + progress * (target_lr - initial_lr)
            for param_group in optimizer.param_groups:
                param_group['lr'] = lr
        return warmup_lr_scheduler

# --- Main Training Function (2 Stages) ---
def train_model(model, train_loader, val_loader, num_classes, device, config):
    """Complete 2-Stage Training Loop with Early Stopping."""
    # --- Optimizer ---
    optimizer_name = config["train"]["optimizer_name"]
    if optimizer_name == 'AdamW':
        optimizer = optim.AdamW(model.parameters(), lr=config["train"]["lr_stage1"], weight_decay=config["train"]["weight_decay"])
    else:
        raise ValueError(f"Unsupported optimizer: {optimizer_name}")
    print(f"Using {optimizer_name} optimizer.")

    # --- Loss ---
    criterion = nn.CrossEntropyLoss()
    scaler = torch.cuda.amp.GradScaler(enabled=USE_CUDA)

    # --- Learning Rate Schedulers & Early Stopping ---
    stage1_epochs = config["train"]["stage1_epochs"]
    stage2_epochs = config["train"]["stage2_epochs"]
    num_epochs = stage1_epochs + stage2_epochs

    # Setup warmup for Stage 1 ONLY
    initial_warmup_lr = config["train"]["initial_warmup_lr"]
    warmup_epochs = config["train"]["warmup_epochs"]
    lr_stage1 = config["train"]["lr_stage1"] # Target LR of warmup
    total_iters_stage1 = len(train_loader)
    warmup_scheduler = get_warmup_scheduler(optimizer, warmup_epochs, initial_warmup_lr, lr_stage1, total_iters_stage1)

    # --- Early Stopping ---
    patience = config["train"]["patience"]
    best_val_loss = float('inf')
    epochs_no_improve = 0

    # --- Move Model to Device ---
    model = model.to(device)

    # --- 2-Stage Training Loop ---
    print("--- Starting 2-Stage Training ---")
    for epoch in range(num_epochs):
        is_stage1 = epoch < stage1_epochs

        if is_stage1:
            current_lr = optimizer.param_groups[0]['lr']
            if epoch < warmup_epochs:
                 warmup_scheduler(optimizer, epoch)
                 current_lr = optimizer.param_groups[0]['lr'] # Update after warmup
            current_stage_epoch = epoch
            total_warmup_epochs = warmup_epochs
        else:
            # Stage 2: Adjust LR
            for param_group in optimizer.param_groups:
                param_group['lr'] = config["train"]["lr_stage2"] # VERY low LR
            current_lr = optimizer.param_groups[0]['lr']
            current_stage_epoch = epoch - stage1_epochs # Reset epoch count in Stage 2
            total_warmup_epochs = 0  # No warmup in stage 2

        # Train/validate for one epoch
        is_training = True
        train_loss, train_acc = run_epoch(model, train_loader, criterion, optimizer, scaler, device, is_training, epoch+1, num_epochs, current_lr, warmup_scheduler, current_stage_epoch, total_warmup_epochs)

        is_training = False
        val_loss, val_acc = run_epoch(model, val_loader, criterion, None, scaler, device, is_training, epoch+1, num_epochs, current_lr)

        # --- Early Stopping Check ---
        if val_loss < best_val_loss:
            best_val_loss = val_loss
            epochs_no_improve = 0
            torch.save(model.state_dict(), config["model"]["load_path"])
            print(f"Epoch {epoch+1}: Validation loss improved. Saving model to {config['model']['load_path']}")
        else:
            epochs_no_improve += 1
            print(f"Epoch {epoch+1}: Validation loss did not improve ({epochs_no_improve}/{patience})")
            if epochs_no_improve == patience:
                print("Early stopping triggered.")
                break

        # --- Transition to Stage 2 ---
        if is_stage1 and (epoch == stage1_epochs - 1):
            print("\n--- Transitioning to Stage 2: Fine-tuning all layers ---")
            # Set LR to stage2_lr directly (no warmup)
            for param_group in optimizer.param_groups:
                param_group['lr'] = config["train"]["lr_stage2"] # VERY low LR

    print("\nTraining complete.")

# --- Evaluation Function ---
def evaluate_model(config: Dict[str, Any], final_pred_loader: DataLoader, device: torch.device, class_to_idx_map):
    """Loads model, runs prediction, saves CSV."""

    model = Sentinel2Classifier(config["model"]["num_classes"]).to(device)

    try:
        model.load_state_dict(torch.load(config["model"]["load_path"], map_location=device))
        print(f"Loaded model weights from {config['model']['load_path']}")
    except FileNotFoundError:
        print(f"Error: Model weights not found at {config['model']['load_path']}")
        return
    except Exception as e:
        print(f"Error loading model: {e}")
        return

    model.eval()
    predictions = []
    image_ids = []

    with torch.no_grad():
        for images, _, paths in tqdm(final_pred_loader, desc="Predicting"):
            if images is None:
                print("Skipping batch due to None image data.")
                continue

            images = images.to(device)
            outputs = model(images)
            _, predicted = torch.max(outputs.data, 1)
            predictions.extend(predicted.cpu().numpy())
            image_ids.extend([Path(p).stem for p in paths])

    # Map predictions to class names
    idx_to_class = {v: k for k, v in class_to_idx_map.items()}
    predicted_classes = [idx_to_class[i] for i in predictions]

    # Create DataFrame
    df = pd.DataFrame({'test_id': image_ids, 'label': predicted_classes})
    df['test_id'] = df['test_id'].str.replace('test_', '', regex=False)  # Clean test_id

    # Save to CSV
    csv_path = config["prediction"]["predictions_csv_path"]
    df.to_csv(csv_path, index=False)
    print(f"Predictions saved to {csv_path}")

# --- Main ---
if __name__ == '__main__':
    # Setup output directory
    if not os.path.exists('./outputs'):
        os.makedirs('./outputs')

    # Determine num_classes and create data loaders

    # Create the model
    model = Sentinel2Classifier(CONFIG["model"]["num_classes"])

    # Train the model
    train_model(model, train_loader, val_loader_split, CONFIG["model"]["num_classes"], DEVICE, CONFIG)

    # Evaluate the model
    evaluate_model(CONFIG, final_pred_loader, DEVICE, class_to_idx_map)

    print("Training and inference complete.")
